{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "file_path = 'x_train/'\n",
    "img_number = 0\n",
    "for i in os.listdir(file_path):\n",
    "    if '.png' in i:\n",
    "        img_number += 1\n",
    "print(img_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list()\n",
    "for i in range(img_number):\n",
    "    img_path = 'x_train/%s.png' % str(i)\n",
    "    img = img_load(img_path)\n",
    "    X_train.append(img)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"x_train.txt\", \"wb\") as fp:\n",
    "    pickle.dump(X_train, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"x_train.txt\", \"rb\") as fp:\n",
    "    X_train = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'x_test/'\n",
    "img_number = 0\n",
    "for i in os.listdir(file_path):\n",
    "    if '.png' in i:\n",
    "        img_number += 1\n",
    "print(img_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = list()\n",
    "for i in range(img_number):\n",
    "    img_path = 'x_test/%s.png' % str(i)\n",
    "    img = img_load(img_path)\n",
    "    X_test.append(img)\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"x_test.txt\", \"wb\") as fp:\n",
    "    pickle.dump(X_test, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load('../y_train.npy') \n",
    "y_train = y_train.tolist()\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"y_train.txt\", \"wb\") as fp:\n",
    "    pickle.dump(y_train, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.load('../y_test.npy') \n",
    "y_test = y_test.tolist()\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"y_test.txt\", \"wb\") as fp:\n",
    "    pickle.dump(y_test, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_list, y_list, transform):\n",
    "        self.X_list = X_list\n",
    "        self.y_list = y_list\n",
    "        self.transform = transform\n",
    "        if len(self.X_list) == len(self.y_list):\n",
    "            print('len(X_list) == len(y_list)')\n",
    "        else:\n",
    "            print('len(X_list) != len(y_list)')\n",
    "        print('transform: %s' % self.transform)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        if self.transform != None:\n",
    "            X = self.transform(self.X_list[index])\n",
    "            y = self.y_list[index]\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = ListData(X_train, y_train, transform)\n",
    "print(len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = ListData(X_test, y_test, transform)\n",
    "print(len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset=data_train,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset=data_test,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_loader_test:\n",
    "    X_test, y_test = data\n",
    "    print(y_test)\n",
    "    img = torchvision.utils.make_grid(X_test) \n",
    "    img = img.numpy().transpose(1, 2, 0)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 192, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(192, 384, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(256, 256, 3),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = AlexNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('cuda')\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iis/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "loss: 0.0035361170352126163\n",
      "training accuracy: 0.9338166666666666\n",
      "testing accracy: 0.9452\n",
      "\n",
      "epoch: 2\n",
      "loss: 0.0026169257409870625\n",
      "training accuracy: 0.9515\n",
      "testing accracy: 0.9432\n",
      "\n",
      "epoch: 3\n",
      "loss: 0.002220741856408616\n",
      "training accuracy: 0.9590166666666666\n",
      "testing accracy: 0.966\n",
      "\n",
      "epoch: 4\n",
      "loss: 0.0019065210017375647\n",
      "training accuracy: 0.9652666666666667\n",
      "testing accracy: 0.9644\n",
      "\n",
      "epoch: 5\n",
      "loss: 0.0016856802742307385\n",
      "training accuracy: 0.9696666666666667\n",
      "testing accracy: 0.9666\n",
      "\n",
      "epoch: 6\n",
      "loss: 0.0014673213980160654\n",
      "training accuracy: 0.9731333333333333\n",
      "testing accracy: 0.9691\n",
      "\n",
      "epoch: 7\n",
      "loss: 0.0014091241358003268\n",
      "training accuracy: 0.9733833333333334\n",
      "testing accracy: 0.9683\n",
      "\n",
      "epoch: 8\n",
      "loss: 0.0013179978412265578\n",
      "training accuracy: 0.9758\n",
      "testing accracy: 0.9712\n",
      "\n",
      "epoch: 9\n",
      "loss: 0.0012128471214324235\n",
      "training accuracy: 0.9774\n",
      "testing accracy: 0.9676\n",
      "\n",
      "epoch: 10\n",
      "loss: 0.0011369827458945414\n",
      "training accuracy: 0.9789666666666667\n",
      "testing accracy: 0.9713\n",
      "\n",
      "epoch: 11\n",
      "loss: 0.0011587418791217108\n",
      "training accuracy: 0.9782333333333333\n",
      "testing accracy: 0.9745\n",
      "\n",
      "epoch: 12\n",
      "loss: 0.0010693712498682242\n",
      "training accuracy: 0.97985\n",
      "testing accracy: 0.9731\n",
      "\n",
      "epoch: 13\n",
      "loss: 0.0009818197441287338\n",
      "training accuracy: 0.9816333333333334\n",
      "testing accracy: 0.9736\n",
      "\n",
      "epoch: 14\n",
      "loss: 0.0009587292420212179\n",
      "training accuracy: 0.9824\n",
      "testing accracy: 0.973\n",
      "\n",
      "epoch: 15\n",
      "loss: 0.0009306983334943652\n",
      "training accuracy: 0.9835166666666667\n",
      "testing accracy: 0.9739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for data in data_loader_train:\n",
    "        X_train, y_train = data\n",
    "        X_train, y_train = Variable(X_train).cuda(), Variable(y_train).cuda()\n",
    "        outputs = model(X_train) \n",
    "        pred = torch.max(outputs.data, 1)[1]\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data[0].item()\n",
    "        running_correct += torch.sum(pred==y_train.data).item()\n",
    "    testing_correct = 0\n",
    "    for data in data_loader_test:\n",
    "        X_test, y_test = data\n",
    "        X_test, y_test = Variable(X_test).cuda(), Variable(y_test).cuda()\n",
    "        outputs = model(X_test)\n",
    "        pred = torch.max(outputs.data, 1)[1]\n",
    "        testing_correct += torch.sum(pred==y_test.data).item()\n",
    "    print('epoch: %s' % (str(epoch + 1)))\n",
    "    print('loss: %s' % str(running_loss / len(data_train)))\n",
    "    print('training accuracy: %s' % str(running_correct / len(data_train)))\n",
    "    print('testing accracy: %s' % str(testing_correct / len(data_test))) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/AlexNet')\n",
    "model = torch.load('models/AlexNet')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
